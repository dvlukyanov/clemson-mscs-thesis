{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "\n",
    "seed=12345\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.convolutional_layer = nn.Sequential(            \n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "                        \n",
    "            nn.Conv2d(128, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=8192, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(in_features=256, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional_layer(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the corresponding data partition as [type, class, item] and transorm it into a PyTorch dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(os.path.join(data_path, 'partition_0.pkl'), 'rb')\n",
    "data = pkl.load(data_file)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        tuples = [(image, label) for label in data.keys() for image in data[label]]\n",
    "        random.shuffle(tuples)\n",
    "        self.data, self.labels = zip(*tuples)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx]) if self.transform else self.data[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = ImageDataset(data['train'], transform)\n",
    "test_dataset = ImageDataset(data['test'], transform)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 1.288. Train accuracy: 41.86%. Test accuracy: 51.40%\n",
      "Epoch: 2. Loss: 0.962. Train accuracy: 56.86%. Test accuracy: 56.80%\n",
      "Epoch: 3. Loss: 0.652. Train accuracy: 74.24%. Test accuracy: 62.30%\n",
      "Epoch: 4. Loss: 0.525. Train accuracy: 80.82%. Test accuracy: 62.70%\n",
      "Epoch: 5. Loss: 0.430. Train accuracy: 86.02%. Test accuracy: 64.00%\n",
      "Epoch: 6. Loss: 0.413. Train accuracy: 87.18%. Test accuracy: 64.90%\n",
      "Epoch: 7. Loss: 0.400. Train accuracy: 88.18%. Test accuracy: 64.90%\n",
      "Epoch: 8. Loss: 0.399. Train accuracy: 88.22%. Test accuracy: 64.90%\n",
      "Epoch: 9. Loss: 0.397. Train accuracy: 88.24%. Test accuracy: 64.90%\n",
      "Epoch: 10. Loss: 0.397. Train accuracy: 88.24%. Test accuracy: 64.90%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    correct_predictions_train = 0\n",
    "    total_samples_train = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted_train = torch.max(outputs, 1)\n",
    "        total_samples_train += labels.size(0)\n",
    "        correct_predictions_train += (predicted_train == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    accuracy_train = 100 * correct_predictions_train / total_samples_train\n",
    "\n",
    "    correct_predictions_test = 0\n",
    "    total_samples_test = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted_test = torch.max(outputs, 1)\n",
    "            total_samples_test += labels.size(0)\n",
    "            correct_predictions_test += (predicted_test == labels).sum().item()\n",
    "\n",
    "    accuracy_test = 100 * correct_predictions_test / total_samples_test\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}. Loss: {running_loss / 100:.3f}. Train accuracy: {accuracy_train:.2f}%. Test accuracy: {accuracy_test:.2f}%')\n",
    "\n",
    "    scheduler.step()\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the final accuracy on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 64.9 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct / total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
